# Hono + Cloudflare Workers + LLM Integration

## ðŸŽ¯ How It Works

Your Cloudflare Worker now uses **Hono** as the web framework, which provides:

- âœ… **Clean API routes** - RESTful endpoints
- âœ… **Middleware support** - CORS, logging, etc.
- âœ… **Type safety** - Full TypeScript support
- âœ… **Edge performance** - Runs on Cloudflare's global network

## ðŸš€ API Endpoints

### Health Check

```bash
GET /health
```

### MCP Tools

```bash
GET /mcp/tools/list          # List all available tools
POST /mcp/tools/add         # Add new MCP server
```

### LLM Integration

```bash
POST /llm/chat              # Chat with LLM + MCP context
POST /llm/execute-tool      # Execute MCP tool directly
```

## ðŸ”§ Setup Steps

### 1. Install Dependencies

```bash
npm install hono
```

### 2. Set Environment Variables

```bash
# Set OpenAI API key
wrangler secret put OPENAI_API_KEY

# Set encryption key for KV
wrangler secret put ENCRYPTION_KEY
```

### 3. Create KV Namespace

```bash
wrangler kv:namespace create "MCP_CONFIG"
wrangler kv:namespace create "MCP_CONFIG" --preview
```

### 4. Update wrangler.jsonc

Replace the placeholder KV namespace IDs with actual ones from step 3.

### 5. Deploy

```bash
npm run deploy
```

## ðŸ’¬ Usage Examples

### Chat with LLM + MCP Context

```bash
curl -X POST https://your-worker.workers.dev/llm/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Help me create a GitHub repository",
    "model": "gpt-4",
    "userId": "U123456"
  }'
```

### Execute MCP Tool

```bash
curl -X POST https://your-worker.workers.dev/llm/execute-tool \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "U123456",
    "serverName": "GitHub",
    "toolName": "create_repo",
    "parameters": {"name": "my-new-repo"}
  }'
```

## ðŸŽ‰ Benefits

- **Serverless** - No server management
- **Global edge** - Fast worldwide
- **Cost effective** - Pay per request
- **Scalable** - Handles any load
- **Secure** - Encrypted storage
- **Type safe** - Full TypeScript support
